import argparse
from utils import get_bound_data
from utils import load_bound_data
from TFwide_compensation import get_activations_low_mem
from TFwide_compensation import split_embeddings_by_domains
from keras.models import load_model
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from score_motifs import motif_scores


def TFwide_embeddings(datapath, modelpath):
    # Load the bound data.
    # Assumption: The bound data is pre-calculated.
    # The bound data is extracted in main.
    protein_list = ['DUXBL', 'Ascl1', 'Ngn2', 'CDX2', 'BHLHB8', 'FOXA1', 'DLX6', 'SOX2', 'SOX15','RHOX11', 'SIX6']
    # protein_list = ['CDX2']
    df_list = []  # Empty list that will store all the data frames generated by split_embeddings_by_domains
    for protein in protein_list:
        # Define the path the specific TF files:
        datapath_curr = datapath + protein + '.chr10'
        print datapath_curr

        # Load the bound datasets
        input_data = load_bound_data(datapath_curr)
        # Extract and save the embeddings of bound and unbound sets to file.
        # Defining the model
        try:
            modelpath_curr = modelpath + protein + '.NIH3T3a.chrom.adam.05.hdf5'
            print modelpath_curr
            model = load_model(modelpath_curr)
            activations = get_activations_low_mem(model, input_data)

        except:
            modelpath_curr = modelpath + protein + '.ES_ATAC.chrom.adam.05.hdf5'
            print modelpath_curr
            model = load_model(modelpath_curr)
            activations = get_activations_low_mem(model, input_data)
            if protein == 'SOX2':
                print protein
                print activations

        outpath = datapath_curr + '.activations'
        np.savetxt(outpath, activations)
        domains = np.loadtxt(datapath_curr + ".domains")

        # Extract domain calls at bound sites.
        labels = np.loadtxt(datapath_curr + ".labels")
        domains_at_bound = domains[labels == 1]

        df_list.append(split_embeddings_by_domains(activations, domains_at_bound, protein))
        dat = pd.concat(df_list)
    dat.to_csv(datapath + '.embeddings', sep="\t")
    dat = pd.read_csv(datapath + '.embeddings', sep="\t")

    sns.set_style('ticks')
    fig, ax = plt.subplots()
    fig.subplots_adjust(left=.15, bottom=.15, right=.95, top=.95)
    sns.boxplot(hue=dat['chromatin'], y=dat['score'], x=dat['protein'], palette='RdBu',
                showfliers=False)
    for axis in ['top', 'bottom', 'left', 'right']:
        ax.spines[axis].set_linewidth(1)
    plt.xticks(fontsize=10)
    plt.yticks(fontsize=10)
    plt.ylabel('Sequence sub-network activations', fontsize=12)
    plt.xlabel('Transcription Factor', fontsize=12)
    sns.despine()
    fig.set_size_inches(7, 3)
    plt.savefig(datapath + "scores_at_domains_weighted.pdf")
    plt.show()


def main():
    # Sample run:
    # python tfwide_figures/figures.py ~/Documents/tempACI_files/tfs/ ~/Documents/tempACI_files/tfs/test.chr10/ 1
    #
    parser = argparse.ArgumentParser(description="Characterize the sequence and chromatin\
                                             predictors of induced TF binding",
                                     prog='interpretNN')
    # adding parser arguments
    parser.add_argument("modelpath", help="Input a trained model in '.hdf5' format")
    parser.add_argument("datapath", help="File path and prefix to the data files")
    parser.add_argument("numc", help="The number of input chromatin data tracks used for training")
    # no optional arguments added yet.
    parser.add_argument("--sequence", action='store_true', help="Interpret the sequence sub-network (Figures 4)")
    parser.add_argument("--chromatin", action='store_true', help="Interpret the chromatin sub-network (Figures 5")
    parser.add_argument("--joint", action='store_true', help="Plot the sequence-chromatin contributions (Figures 3)")
    parser.add_argument("--metrics", action='store_true', help="Plot the global metrics (Figures 2)")
    args = parser.parse_args()

    # Load the model, as well as extract the bound data for the joint embeddings
    # model = load_model(args.model)

    # print 'Loading and extracting the subset of bound sites...'
    # get_bound_data(args.datapath + 'Ascl1.chr10')
    # get_bound_data(args.datapath + 'Ngn2.chr10')

    print 'Done loading...'
    TFwide_embeddings(args.datapath, args.modelpath)
    # motif_scores(args.modelpath)


if __name__ == "__main__":
    main()